<html lang="en">
	<head>
		<meta charset="UTF-8">
		<title>A Primitive Guide to FFT</title>
		<link rel="stylesheet" href="prism.css">
		<link rel="stylesheet" href="../style.css">
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
				tex2jax: {
					inlineMath: [['$','$']],
					displayMath: [['$$','$$']],
					processEscapes: true
				}
			});
		</script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
		<script src="prism.js"></script>
	</head>

	<body>
		<div id="title">A Primitive Guide to FFT</div>

		<div id="preamble">
				$$
				\newcommand{\om}{\omega}
				$$
		</div>

		<div id="warning">
			<div class="subheading">Warning: This article is not finished</div>
			This article is still being written and edited. There are most likely many mistakes and typos.
		</div>

		<div id="toc">
			<div class="heading">Table of Contents</div>
			<ul>
				<li><a href="#toc0">Introduction</a></li>
				<li><a href="#toc1">Pre-Requisite Knowledge</a></li>
				<li><a href="#toc2">Multiplying Polynomials</a></li>
				<li><a href="#toc3">Sampling and Interpolating</a></li>
				<li><a href="#toc4">Speedup Overview</a></li>
				<li><a href="#toc5">Trying to Sample Quickly</a></li>
				<li><a href="#toc6">Primitive Roots of Unity</a></li>
				<li><a href="#toc7">Sampling Quickly</a></li>
				<li><a href="#toc8">Reducing Interpolating to Sampling</a></li>
				<li><a href="#toc9">Interpolating Quickly</a></li>
				<li><a href="#toc10">Complex Numbers</a></li>
				<li><a href="#toc11">Implementation - Complex Numbers</a></li>
				<li><a href="#toc12">The Integers Modulo A Prime Number</a></li>
			</ul>
		</div>

		<div id="main">

			<div id="toc0" class="section">
				<div class="heading">Introduction</div>
				<div class="subsection">

					<p>
						In competitive programming, FFT or Fast Fourier Transform is a technique that speeds up polynomial multiplication from $O(n^2)$ to $O(n \log n)$. This is useful because polynomial multiplication can be used to solve a variety of problems.
					</p>

					<p>
						FFT is a fairly advanced topic, in the sense that it rarely shows up in problemsets, and if it does, it appears in more difficult problems.
					</p>

					<p>
						While this article uses terms like "Theorem" and "Proof", you should expect its rigorousness to be around that of a high school math class.
					</p>
				</div>
			</div>

			<div id="toc1" class="section">
				<div class="heading">Pre-Requisite Knowledge</div>
				<div class="subsection">

					<p>
						Required:
					</p>

<ul>

<li>Time complexity</li>

<li>Summation ($\sum$) notation</li>

<li>Polynomials</li>

<li>Divide and conquer</li>

</ul>

					<p>
						Helpful, but not required:
					</p>

<ul>

<li>Complex numbers and trignometry</li>

<li>Number theory, specifically, $\mathbb Z/p\mathbb Z$</li>

</ul>

					<p>
						This article features code in C++.
					</p>
				</div>
			</div>

			<div id="toc2" class="section">
				<div class="heading">Multiplying Polynomials</div>
				<div class="subsection">

					<div class="block">
						<div class="block-heading">Definition - Polynomial</div>

					<p>
						A polynomial $f(x)$ of degree $n$ is defined as $$f(x) = a_0 + a_1x + a_2x^2 + \dots + a_nx^n$$
					</p>

					<p>
						where $a_0, \dots, a_n$ are numbers called coefficients.
					</p>
					</div>

					<p>
						Often, this definition includes $a_n \neq 0$, but we won't. This allows us to "upgrade" polynomials to a higher degree by adding $0x^{n + 1} + 0x^{n + 2} + \dots$ to the end of it.
					</p>

					<p>
						We can multiply polynomials to get a new polynomial:
					</p>

					<p>
						$$\begin{align}h(x) &= f(x)g(x) \\     &=(a_0 + a_1x + \dots + a_nx^n)(b_0 + b_1x + \dots + b_nx^n) \\     &= \sum_{i = 0}^n \sum_{j = 0}^n a_ib_jx^{i+j}\end{align}$$
					</p>

					<p>
						If we want to find the $k$-th coefficient of $h(x)$, denoted as $c_k$, we can rearrange the formula to get
					</p>

					<p>
						$$ c_k = \sum_{i = 0}^k a_ib_{k - i} $$
					</p>

					<p>
						Applying the formula directly, we need to add $k$ terms to compute $c_k$. To compute all coefficients, the time required is $O(n^2)$. If we avoid this direct formula, we can achieve $O(n \log n)$ using FFT.
					</p>
				</div>
			</div>

			<div id="toc3" class="section">
				<div class="heading">Sampling and Interpolating</div>
				<div class="subsection">

					<p>
						Let's say $f(x) = a_0 + a_1x + a_2x^2$ is a second degree polynomial. We don't know it's coefficients, but we know that $f(1) = 123$ and $f(3) = 456$. Is this enough to determine that $f(x)$ is? What if we also knew that $f(4) = 789$? There is a general result related to this:
					</p>

					<div class="block">
						<div class="block-heading">Theorem 1: Uniqueness of Interpolation</div>

					<p>
						Let $f(x)$ be a polynomial with degree $n$ whose coefficients $a_0, \dots, a_n$ are unknown.
					</p>

					<p>
						For any choice of $n + 1$ distinct numbers $s_0, \dots, s_n$, if we know $f(s_0), \dots, f(s_n)$, then uniquely determine $a_0, \dots, a_n$.
					</p>

<a href="proof1.html">Proof</a>
					</div>

					<p>
						Let's call the choice of distinct numbers $s_0, \dots, s_n$ <b>sampling points</b> and the values of $f(s_0), \dots f(s_n)$ <b>samples</b>. The polynomial that satisfies the samples is said to <b>interpolate</b> the samples.
					</p>
				</div>
			</div>

			<div id="toc4" class="section">
				<div class="heading">Speedup Overview</div>
				<div class="subsection">

					<p>
						For the sake of convenience, we'll talk about polynomials of degree $n - 1$ from now on. Now, let's talk about the general strategy we'll use to multiply two multinomial.
					</p>

					<p>
						To multiply $f(x)$ and $g(x)$, we'll first pick some sampling points $s_0, \dots, s_{2n-1}$. Then, we'll evaluate each of them at these sampling points.
					</p>

					<p>
						Now, we'll multiply the samples of $f(x)$ by the corresponding samples of $g(x)$. That is, we calculate $f(s_0)g(s_0), \dots, f(s_{2n -1})g(s_{2n-1})$. From the Theorem above, this is enough to calculate all the coefficients of $f(x)g(x)$.
					</p>

					<p>
						This seems like a roundabout way to do things but surprisingly, each one of these steps takes at most $O(n \log n)$.
					</p>
				</div>
			</div>

			<div id="toc5" class="section">
				<div class="heading">Trying to Sample Quickly</div>
				<div class="subsection">

					<p>
						For some polynomial of degree $n - 1$, let's try to quickly find $n$ samples, that is, pick some $s_0, \dots, s_{k-1}$ and calculate $f(s_0), \dots, f(s_{n-1})$. For now, we'll also require:
					</p>

<ul>

<li>The number of samples is one more than the degree of the polynomial</li>

<li>$n$ is a power of 2</li>

</ul>

					<p>
						We'll see later that this limited form can generalize pretty easily.
					</p>

					<p>
						As an example, we'll try $n = 2$ and $s_0 = 1, s_1 = -1$. That is, we want to compute $f(1)$ and $f(-1)$.
					</p>

					<p>
						We can see that $f(1) = a_0 + a_1 + a_2 + \dots + a_{n-1}$, which is a just the sum of coefficients. However, $f(-1) = a_0 - a_1 + a_2 - \dots + a_{n-1}$, which is the altenating sum of coefficients.
					</p>

					<p>
						If we separate the coefficients that we add from the ones we subtract in the calculation $f(-1)$, we can split $f(x)$ into two polynomials: the even degree-terms and the odd-degree terms. For simplicity, we assume that $n$ is an even number.
					</p>

					<p>
						$$\begin{align}f_{even}(x) &= a_0 + a_2 + \dots + a_{n - 2} \\f_{odd}(x) &= a_1 + a_3 + \dots + a_{n - 1}\end{align}$$
					</p>

					<p>
						With these definitions, we can write two equalities:
					</p>

					<p>
						$$\begin{align}f(1) &= f_{even}(1) + f_{odd}(1) \\f(-1) &= f_{even}(1) - f_{odd}(1)\end{align}$$
					</p>

					<p>
						We've basically converted our original problem of calculating $f(1)$ and $f(-1)$ into two smaller problems: finding $f_{even}(1)$ and $f_{odd}(1)$ at a cost of $O(n)$ for combining the results. We notice that the two smaller problems have both half the size of the polynomial and half the number samples required. If you're familiar with divide and conquer (e.g. mergesort), we've split the problem into two versions that are half the size at a cost of $O(n)$. This yields a total time complexity of $O(n \log n)$.
					</p>

					<p>
						But wait, we've only described a strategy for finding two samples. How can we scale this up to any number of samples? Before we do this, let's try to handle 4 samples. The reason why the above formulas work is because $(-1)^k$ is equal to $1$ for even $k$ and equal to $-1$ for odd $k$. If we wanted to extend this strategy, we'd have to find a number whose square is $-1$.
					</p>

					<p>
						There is a number
					</p>
				</div>
			</div>

			<div id="toc6" class="section">
				<div class="heading">Primitive Roots of Unity</div>
				<div class="subsection">

					<p>
						In general, we want an $n$-th root of the number $1$. This is called an $n$-th root of unity. This isn't too useful since 1
					</p>

					<div class="block">
						<div class="block-heading">Definition - Roots of Unity and Primitivity</div>

					<p>
						Let $n$ be a positive integer.
					</p>

					<p>
						A number $\om_n$ is said to be an <b>n-th root of unity</b> if $\om_n^n =1 $.
					</p>

					<p>
						In addition, a $n$-th root of unity $\om_n$ is said to be <b>primitive</b> if for all $0 < k < n$, $\om_n^k \neq 1$.
					</p>
					</div>

					<p>
						If we're using the real numbers, these don't exist for $n > 2$. That's not really a problem since we can just choose a number system where they do. For now, let's look at the properties of the numbers.
					</p>

					<div class="block">
						<div class="block-heading">Theorem 2: Properties of Primitive Roots of Unity</div>

					<p>
						Let $n$ be an even number, and $\om_n$ be a primitive $n$-th root of unity.
					</p>

<div>

<b>Theorem 2.1:</b> For all $0 < k < n$, the values of $\om_n^k$ are distinct $n$-th roots of unity.

</div>

<div style="margin: 5px 0px 7px 0px">

<b>Theorem 2.2:</b> $\om_{n}^{n/2} = -1$.

</div>

<div>

<b>Theorem 2.3:</b>

<ol style="margin: 10px 2px 0px 2px">

<li>$\om_n^2$ is an $n/2$-th root of unity. Let's call it $\om_{n/2}$.</li>

<li>For all $0 < k < n$, $(\om_n^k)^2 = \om_{n/2}^k$</li>

<li>For all $0 < k < n$, $(\om_n^{k + {n/2}})^2 = \om_{n/2}^k$</li>

</ol>

</div>

<div>

<b>Theorem 2.4:</b> $\om_n^0 + \om_n^1 + \om_n^{2} + \dots + \om_n^{n-1} = 0$.

</div>

<div style="margin-top: 10px">

<a href="proof2.html">Proof</a>

</div>
					</div>
				</div>
			</div>

			<div id="toc7" class="section">
				<div class="heading">Sampling Quickly</div>
				<div class="subsection">

					<p>
						We can now solve the problem of finding $n$ samples from a polynomial of degree $n - 1$.
					</p>

					<p>
						Let's recap what the problem is
					</p>

					<div class="block">
						<div class="block-heading">Sampling Problem Statement</div>

					<p>
						Given $a_0, \dots, a_{n-1}$ which determines $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$, and a choice of $n$ sampling points $s_0, s_1, \dots, s_{n-1}$, we wish to find the samples
					</p>

					<p>
						$$ f(s_0), f(s_1), \dots, f(s_{n-1}) $$
					</p>

					<p>
						where
					</p>

					<p>
						$$\begin{align}f(s_0) &= a_0 + a_1s_0 + a_2s_0^2 + \dots + a_{n-1}s_0^{n-1} \\f(s_1) &= a_1 + a_1s_1 + a_2s_1^2 + \dots + a_{n-1}s_1^{n-1} \\&\phantom{$a_1+a_1s_1+a_2$}     \vdots \\f(s_{n-1}) &= a_1 + a_1s_{n-1} + a_2s_{n-1}^2 + \dots + a_{n-1}s_{n-1}^{n-1} \\\end{align}$$
					</p>
					</div>

					<p>
						We can easily evaluate the $n$ samples in $O(n^2)$ time since it takes $O(n)$ time to calculate a single sample and we have $O(n)$ samples to calculate. In order to speed this up to $O(n \log n)$, we'll have to take advantage of the properties of the primitive roots of unity.
					</p>

					<p>
						Let $n$ be an even number and $m = \frac n2$. Let $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$ be an $n - 1$ degree polyomial. We define two $n - 1$ degree polynomials, $f_e$ keeping only the coefficients at even degree and $f_o$ keeping only the coefficients at odd degree:
					</p>

					<p>
						$$\begin{align}f_e(x) &= a_0 + a_2x + a_4x^2 + \dots+ a_{n-2}x^{m-1}f_o(x)&=a_1+a_3x + a_5x^2 + \dots + a_{n-1}x^{m-1}\end{align}$$
					</p>

					<p>
						Now let $\om_n$ be a primitive $n$-th root of unity. We'll drop the subscript $_n$ for now for convenience. We can conveniently evaluate $f(\om^k)$ from just $f_e(\om^{2k})$ and $f_o(\om^{2k})$:
					</p>

					<p>
						$$\begin{align}f_e(\om^{2k}) + \om^kf_o(\om^{2k})  &= \left(a_0 + a_2\om^{2k} + \dots + a_{n-2}\om^{2k(m - 1)}\right)+\om^k\left(a_1+a_3\om^{2k}+\dots+a_{n-1}\om^{2k(m-1)}\right) \\  &= \left(a_0+a_2\om^{2k}+\dots+a_{n-2}\om^{(n-2)k}\right)+\left(a_1\om^k+a_3\om^{3k}+\dots+a_{n-1}\om^{(n-1)k}\right) \\  &= a_0+a_1\om^k+a_2\om^{2k}+a_3\om^{3k}+\dots+a_{n-2}\om^{(n-2)k}+a_{n-1}\om^{(n-1)k} \\  &= f(\om^k)\end{align}$$
					</p>

					<p>
						Let's bring the subscript $_n$ back so we can manipulate the result that we found. If $\om_n$ is a primitive $n$-th root of unity and $m = \frac n2$, then
					</p>

					<p>
						$$\begin{align}f(\om_n^k) &= f_e(\om_n^{2k}) + \om_n^k f_o(\om_n^{2k}) \\           &= f_e((\om_n^k)^2) + \om_n^kf_o((\om_n^k)^2) \\           &= f_e(\om_m^k)+\om_n^kf_o(\om_m^k)\end{align}$$
					</p>

					<p>
						This formula works for all $0 \leq k < n$, but if we restrict $k$ to the range $0 \leq k < m$ and consider both $k$ and $k + m$, we find a very special pattern:
					</p>

					<p>
						$$ f(\om_n^k) = f_e(\om_m^k)+\om_n^kf_o(\om_m^k) $$
					</p>

					<p>
						as expected, but
					</p>

					<p>
						$$\begin{align}f(\om_n^{k + m}) &= f_e(\om_n^{k + m})+\om_n^{k + m}f_o(\om_m^{k + m}) \\                 &= f_e(\om_m^k\om_m^m) + \om_n^n \om_n^k f_o(\om_m^k\om_m^m) \\                 &= f_e(\om_m^k) - \om_n^k f_o(\om_m^k)\end{align}$$
					</p>

					<p>
						To recap, we've found that
					</p>

					<div class="block">
						<div class="block-heading">Sampling Reduction Formula</div>

					<p>
						If $n$ is an even number, $m = \frac n2$, and
					</p>

					<p>
						$$\begin{align}f(x)   &= a_0 + a_1x + a_2x^2+ \dots + a_{n-1}x^{n-1} \\f_e(x) &= a_0 + a_2x + a_4x^2 + \dots+ a_{n -2}x^{m-1} \\f_o(x) &= a_1+a_3x + a_5x^2 + \dots + a_{n-1}x^{m-1}\end{align}$$
					</p>

					<p>
						and $\om_n$ is a primitive $n$-th root of unity, then for all $0 \leq k < m$,
					</p>

					<p>
						$$\begin{align}f(\om_n^k)     &= f_e(\om^k_m) + \om^k_n f_o(\om^k_m) \\f(\om_n^{k+m}) &= f_e(\om^k_m) - \om^k_nf_o(\om^k_m)\end{align}$$
					</p>
					</div>

					<p>
						This is an extremely important formula. This means that if we need to sample $f(x)$ at $\om_{2n}^0, \om_{2n}^1, \dots \om_{2n}^{2n-1}$, we can reduce this into the problem of sampling $f_e(x)$ and $f_o(x)$ at $\om_n^0, \om_n^1, \dots \om_n^{n-1}$ with a cost of $O(n)$ steps.
					</p>

					<p>
						At first glance, this doesn't help at all. In order to calculate $2n$ samples, we need to calculate $n$ samples for each of the functions $f_e$ and $f_o$, which is still $2n$ samples in total.
					</p>

					<p>
						What if we kept using this formula over and over again? Let $n$ be a power of two, say $n = 2^k$. Suppose we have a polynomial of degree $n - 1$ and want to find $n$ samples. With a cost of $O(n)$ steps, we can reduce the problem into finding $\frac{n}{2}$ samples for $2$ polynomials of degree $\frac{n}{2} - 1$. If we apply the formula to each of the smaller polynomials, then with a cost of $2 \times \frac{n}{2} = O(n)$, we can reduce the problem further to finding $\frac{n}{4}$ samples for $4$ polynomials of degree $\frac{n}{4} - 1$.
					</p>

					<p>
						Eventually, after $k$ iterations of this, with each iteration incurring a cost of $O(n)$ steps, the problem is reduced to finding one sample for $n$ polynomials each of degree $0$. This is now trivial to do since a sample of a polynomial $f(x) = a_0$ of degree $0$ is just $a_0$, so this step takes $O(n)$ time. In total, since $n = 2^k$, then $k = \log n$, so we spent $O(n) \times O(\log n) = O(n \log n)$ time reducing the problem to the trivial form, and $O(n)$ time solving the trivial form. Therefore, we've found a way to take $n$ samples in just $O(n)$ time.
					</p>

					<div class="block">
						<div class="block-heading">Sampling Algorithm</div>

					<p>
						Let $n$ be a power of $2$, $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$ be a polynomial of degree $n - 1$ and $\om_{n}$ be a primitive $n$-th root of unity.
					</p>

					<p>
						To calculate $n$ samples $f(\om_n^0), f(\om_n^1), \dots, f(\om_n^{n-1})$:
					</p>

<ul>

<li>If $n = 1$, then the only sample we need is $f(\om_1^0) = f(1) = a_0$.</li>

<li>

					<p>
						Otherwise, let $m = \frac n2$ and $$\begin{align}f_e(x) &= a_0 + a_2x + a_4x^2 + \dots + a_{n-1}x^{m-1}\\f_o(x)&=a_1+a_3x+a_5x^2+\dots+a_nx^{m-1}\end{align}$$
					</p>

					<p>
						We recursively apply this algorithm on $f_e(x)$ and $f_o(x)$ to find $f_e(\om_{m}^0), f_e(\om_{m}^1), \dots, f_e(\om_{m}^{m - 1})$ and $f_o(\om_{m}^0), f_o(\om_{m}^1), \dots, f_o(\om_{m}^{m - 1})$.
					</p>

					<p>
						From these samples, we can calculuate $f(\om_n^0), f(\om_n^1), \dots, f(\om_n^{n-1})$:
					</p>

					<p>
						For all $0 \leq k < m$,
					</p>

					<p>
						$$\begin{align}f(\om_n^k)     &= f_e(\om^k_m) + \om^kf_o(\om^k_m) \\f(\om_n^{k+m}) &= f_e(\om^k_m) - \om^kf_o(\om^k_m)\end{align}$$
					</p>

</li>

</ul>
					</div>

					<p>
						Of course, when we sample a polynomial, it's not always going to have a degree that's one less than a power of $2$. This isn't a problem since we can just "upgrade" the polynomial to one less than the next power of $2$.
					</p>

					<p>
						For example, if we have a polynomial $f(x) = a_0 + \dots + a_nx^n$ of degree $n$ and $2^k$ is the smallest power of $2$ at least as big as $n - 1$, then we can interpret $f(x)$ as $f(x) = a_0 + \dots a_nx^n + 0x^{n+1} + \dots + 0x^{2^k - 1}$.
					</p>

					<p>
						In the worst case, the new degree and the number of samples we'll have to take is doubled. This is fine because this is just a constant factor.
					</p>
				</div>
			</div>

			<div id="toc8" class="section">
				<div class="heading">Reducing Interpolating to Sampling</div>
				<div class="subsection">

					<p>
						While sampling can be easily done in $O(n^2)$, it seems like interpolating in any time complexity is a daunting task. However, in this section, we'll find that through the magic of primitive roots of unity, interpolating is just sampling in disguise.
					</p>

					<p>
						Let's first recap what the problem asks us to do.
					</p>

					<div class="block">
						<div class="block-heading">Interpolating Problem Statement</div>

					<p>
						Let $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$ be a polynomial of degree $n - 1$.
					</p>

<br/>

					<p>
						Given $n$ sample points $s_0, \dots, s_{n-1}$ and $n$ samples $v_0, \dots, v_{n-1}$ where it is known that $f(s_0) = v_0, f(s_1) = v_1, \dots, f(s_{n-1}) = v_{n-1}$, we wish to find $a_0, \dots a_{n-1}$.
					</p>

<br/><br/>

					<p>
						In other words, we want to solve the system of equations
					</p>

					<p>
						$$\begin{align}a_0 + a_1s_0 + a_2s_0^2 + \dots + a_{n-1}s_0^{n-1} &= v_0 \\a_1 + a_1s_1 + a_2s_1^2 + \dots + a_{n-1}s_1^{n-1} &= v_1 \\\vdots\phantom{+$a_{n-1}s_1^{n-1}$}& \\a_1 + a_1s_{n-1} + a_2s_{n-1}^2 + \dots + a_{n-1}s_{n-1}^{n-1} &= v_{n-1} \\\end{align}$$
					</p>
					</div>

					<p>
						We note that by Uniqueness of Interpolation, that we're guaranteed exactly one possible value for $a_0, \dots, a_n$.
					</p>

					<p>
						Let's prove an interesting property about combining interpolating problems:
					</p>

					<div class="block">
						<div class="block-heading">Theorem - Additivity of Interpolation</div>

					<p>
						Let $f(x)$ and $g(x)$ be polynomials of degree $n - 1$.
					</p>

					<p>
						Suppose we are given sample points $s_0, \dots, s_n$ and we know that:
					</p>

					<p>
						$$u_0 = f(s_0), u_1 = f(s_1), \dots, u_{n-1} = f(s_{n-1}) \\v_0 = f(s_0), v_1 = f(s_1), \dots, v_{n-1} = f(s_{n-1})$$
					</p>

					<p>
						and we've found $f(x)$ and $g(x)$.
					</p>

					<p>
						Then the polynomial $h(x)$ that interpolates the samples $(u_0 + v_0), (u_1 + v_1), \dots, (u_{n-1}, v_{n-1})$ is $h(x) = f(x) + g(x)$.
					</p>
					</div>

					<p>
						The proof of this is pretty simple. At each of the sample points $s_i$ where $0 \leq i < n$, $h(s_i) = f(s_i) + g(s_i) = u_i + v_i$. Again, by the Uniquness of Interpolation, $h(x) = f(x) + g(x)$ is the only possible polynomial that interpolates the samples.
					</p>

					<p>
						This theorem seems trivial but it lets us break down the problem into easier subproblems. Let $v_0, \dots, v_n$ be samples. For $0 \leq k < n$, we'll define the <i>$k$-th partial sample set</i> to be $0, \dots, 0, v_k, 0, \dots, 0$. In other words, it's only the $k$-th sample and every other sample has been set to $0$.
					</p>

					<p>
						If we can solve the interpolation problem for all of the partial sample sets, we'll can just add the interpolating polynomials together to get the interpolation of $v_0, \dots, v_n$.
					</p>

					<p>
						Recall that we've picked $s_0, \dots, s_{n-1}$ to be $\om_n^0, \dots, \om_n^{n-1}$ where $\om_n$ is a primitive $n$-th root of unity. Now let's try to interpolate the $0$-th partial sample set, that is, we want to solve the system
					</p>

					<p>
						$$\begin{align}a_0 + a_1 + a_2 + \dots + a_{n-1}                                         &= v_0 \\a_0 + a_1\om_n^1 + a_2\om_n^2 + \dots + a_{n-1}\om_n^{n-1}                &= 0 \\            \vdots\phantom{+$a_{n-1}s_1^{n-1}$}               & \\a_0 + a_1\om_n^{n-1} + a_2\om_n^{2(n-1)} + \dots + a_{n-1}\om_n^{(n-1)^2} &= 0 \\\end{align}$$
					</p>

					<p>
						This doesn't make the problem any easier, but if we try something silly, we'll see that everything works out. If we set $a_0 = a_1 = a_2 = \dots = a_{n-1} = \frac 1n v_0$, then we see that indeed $a_0 + a_1 + a_2 + \dots + a_{n-1} = \frac 1nv_0 + \dots + \frac 1nv_0 = \frac 1nv_0(n) = v_0$.
					</p>

					<p>
						But do we satisfy the other equations? Well for $0 < k < n$, we have
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   a_0 + a_1\om_n^k + a_2\om_n^{2k} + \dots + a_{n-1}\om_n^{(n-1)k} \\&= \tfrac 1nv_0 + \tfrac 1nv_0\om_n^k + \tfrac 1nv_0\om_n^{2k} + \dots + \tfrac 1nv_0\om_n^{(n-1)k} \\&= \tfrac 1nv_0 \left(1 + \om_n^k + \om_n^{2k} + \dots + \om_n^{(n-1)k} \right)\end{align}$$
					</p>

					<p>
						By the fourth primitive root of unity property, for all $0 < k < n$, $\om_n^0 + \om_n^k + \om_n^{2k} + \dots + \om_n^{(n-1)k} = 0$, so
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   \tfrac 1nv_0 \left(1 + \om_n^k + \om_n^{2k} + \dots + \om_n^{(n-1)k}\right) \\&= \tfrac 1nv_0 (0) \\&= 0\end{align}$$
					</p>

					<p>
						Now that we've solved the $0$-th partial sample set, we can also solve the $k$-th partial sample set for $0 < k < n$. This time, we want to solve the system
					</p>

					<p>
						$$\begin{align}a_0 + a_1 + a_2 + \dots + a_{n-1}                                         &= 0 \\                         \vdots\phantom{+$a_{n-1}s_1^{n-1}$}              & \\a_0 + a_1\om_n^k + a_2\om_n^{2k} + \dots + a_{n-1}\om_n^{(n-1)k}          &= v_k \\                         \vdots\phantom{+$a_{n-1}s_1^{n-1}$}              & \\a_0 + a_1\om_n^{n-1} + a_2\om_n^{2(n-1)} + \dots + a_{n-1}\om_n^{(n-1)^2} &= 0 \\\end{align}$$
					</p>

					<p>
						We can do something similar, but instead of setting $a_0 = \dots = a_n = \frac 1nv_0$, we'll set
					</p>

					<p>
						$$\begin{align}a_0 &= \tfrac 1nv_k \\a_1 &= \tfrac 1nv_k\om_n^{-k}\\ a_2 &= \tfrac 1nv_k\om_n^{-2k}\\ &\phantom{/}\vdots\\ a_{n-1} &= \tfrac 1nv_k \om_n^{-(n-1)k}\end{align}$$
					</p>

					<p>
						That way, we have
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   a_0 + a_1\om_n^k + a_2\om_n^{2k} + \dots + a_{n-1}\om^{(n-1)k} \\&= \tfrac 1nv_k + \tfrac 1nv_k\om_n^{-k}\om_n^k + \tfrac 1nv_k\om_n^{-2k}\om_n^{2k}+ \dots+ \tfrac 1nv_k \om_n^{-(n-1)k}\om_n^{-(n-1)k} \\&= \tfrac 1nv_k\left( 1 + \om_n^{-k}\om_n^k + \om_n^{-2k}\om_n^{2k} + \dots + \om_n^{-(n-1)k}\om_n^{(n-1)k}\right)\\&= \tfrac 1nv_k\left(1+1+1+\dots+1\right) \\&= \tfrac 1nv_k(n) \\&= v_k\end{align}$$
					</p>

					<p>
						And see once again for any $i \neq k$,
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   a_0 + a_1\om_n^i + a_2\om_n^{2i} + \dots + a_{n-1}\om_n^{(n-1)i} \\&= \tfrac 1nv_k + \tfrac 1nv_k\om_n^{-k}\om_n^i + \tfrac 1nv_k\om_n^{-2k}\om_n^{2i} + \dots + a_{n-1}\om_n^{-(n-1)k}\om_n^{(n-1)i} \\&= \tfrac 1nv_k \left(1 + \om_n^{-k}\om_n^i + \om_n^{-2k}\om_n^{2i} + \dots + \om_n^{-(n-1)k}\om_n^{(n-1)i}\right) \\&= \tfrac 1nv_k \left(1 + \om_n^{i-k} + \om_n^{2(i-k)} + \dots + \om_n^{(n-1)(i-k)} \right)\end{align}$$
					</p>

					<p>
						Let $j = i - k$, we have
					</p>

					<p>
						$$ \tfrac 1nv_k \left(1 + \om_n^{j} + \om_n^{2j} + \dots + \om_n^{(n-1)j} \right) $$
					</p>

					<p>
						We know that $0 \leq i, k < n$ and $i \neq k$, and there are 2 cases:
					</p>

<ol>

<li>

					<p>
						If $i > k$, then $0 < i - k < n$ or $0 < j < n$. Therefore,
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   \tfrac 1nv_k \left(1 + \om_n^{j} + \om_n^{2j} + \dots + \om_n^{(n-1)j} \right) \\&= \tfrac 1nv_k (0) \\&= 0\end{align}$$
					</p>

					<p>
						as required.
					</p>

</li>

<li>

					<p>
						If $i < k$, then $-n < i - k < 0$ or $-n < j < 0$. Adding $n$ to everything, we get $0 < j + n < n$.
					</p>

					<p>
						As a side note, we note that for any number $c$, $\om_n^{cn} = (\om_n^n)^c = 1^c = 1$.
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   \tfrac 1nv_k \left(1 + \om_n^{j} + \om_n^{2j} + \dots + \om_n^{(n-1)j} \right) \\&= \tfrac 1nv_k \left(1 + \om_n^{j}\om_n^n + \om_n^{2j}\om_n^{2n} + \dots + \om_n^{(n-1)j}\om_n^{(n-1)n}\right) \\&= \tfrac 1nv_k \left(1 + \om_n^{j+n} + \om_n^{2(j + n)} +\dots+\om_n^{(n-1)(j + n)}\right) \\&= \tfrac 1nv_k (0) \\&= 0\end{align}$$
					</p>

					<p>
						as required.
					</p>

</li>

</ol>

					<p>
						To recap,
					</p>

					<div class="block">
						<div class="block-heading">Interpolation Formula</div>

					<p>
						Let $\om_n$ be a primitive $n$-th root of unity.
					</p>

<br/>

					<p>
						Let $v_0, \dots, v_{n-1}$ $n$ samples, with $v_k = f(\om_n^k)$ for all $0 \leq k < n$.
					</p>

<br/>

					<p>
						The solution to the $k$-th partial sample set is $a_i = \frac 1nv_k \om_n^{-ik}$ for all $0 \leq i < n$, that is
					</p>

					<p>
						$$\begin{align}f(x) &= \tfrac 1nv_k + \tfrac 1nv_k\om_n^{-k} + \tfrac 1nv_k\om_n^{-2k} + \dots + \tfrac 1nv_k\om_n^{-(n-1)k} \\     &= \tfrac 1nv_k \left(1 + \om_n^{-k} + \om_n^{-2k} + \dots + \om_n^{-(n-1)k} \right)\end{align}$$
					</p>

					<p>
						By the Additivity of Interpolation, the solution to $a_0, \dots, a_{n-1}$ is the sum of interpolations of all $n$ partial sample sets, that is
					</p>

					<p>
						$$\begin{align}a_0     &= \tfrac1n v_0 + \tfrac1n v_1 + \tfrac1n v_2 + \dots + \tfrac1n v_{n-1} \\a_1     &= \tfrac1n v_0 + \tfrac1n v_1\om_n^{-k} + \tfrac1n v_2\om_n^{-2k} + \dots + \tfrac1n v_{n-1}\om_n^{-(n-1)k} \\a_2     &= \tfrac1n v_0 + \tfrac1n v_1\om_n^{-2k} + \tfrac1n v_2\om_n^{-4k} + \dots + \tfrac1n v_{n-1}\om_n^{-2(n-1)k} \\        &                              \phantom{XXXXXXXXXXXX}\vdots \\a_{n-1} &= \tfrac1n v_0 + \tfrac1n v_1\om_n^{-(n-1)k} + \tfrac1n v_2\om_n^{-2(n-1)k} + \dots + \tfrac1n v_{n-1}\om_n^{-(n-1)^2k} \\\end{align}$$
					</p>

					<p>
						Pulling out $\frac 1n$ from each term, we get
					</p>

					<p>
						$$\begin{align}a_0     &= \tfrac 1n \left( v_0 +  v_1 +  v_2 + \dots +  v_{n-1} \right) \\a_1     &= \tfrac 1n \left( v_0 +  v_1\om_n^{-k} +  v_2\om_n^{-2k} + \dots +  v_{n-1}\om_n^{-(n-1)k} \right) \\a_2     &= \tfrac 1n \left( v_0 +  v_1\om_n^{-2k} +  v_2\om_n^{-4k} + \dots +  v_{n-1}\om_n^{-2(n-1)k} \right) \\        &                           \phantom{XXXXXXXXXXXX}\vdots \\a_{n-1} &= \tfrac 1n \left( v_0 +  v_1\om_n^{-(n-1)k} +  v_2\om_n^{-2(n-1)k} + \dots +  v_{n-1}\om_n^{-(n-1)^2k} \right)\\\end{align}$$
					</p>
					</div>

					<p>
						Ignoring the factor of $\frac 1n$, this equation looks an awful lot like the sampling problem.
					</p>
				</div>
			</div>

			<div id="toc9" class="section">
				<div class="heading">Interpolating Quickly</div>
				<div class="subsection">

					<p>
						We can now use the techniques we used to sample quickly to interpolate quickly. Let's pretend the factor of $\frac 1n$ doesn't exist. Then from the previous section, we found that for all $0 \leq k < n$,
					</p>

					<p>
						$$ a_{k} = v_0 + v_1\om_n^{-k} + v_2\om_n^{-2k} + \dots + v_{n-1}\om_{n-1}^{-(n-1)k} $$
					</p>

					<p>
						This is almost exactly what we wanted to compute when sampling, except $a_k$ and $v_k$ are swapped and the exponents are negative in this version. In fact, if we define a special polynomial
					</p>

					<p>
						$$ v(x) = v_0 + v_1x + v_2x^2 + \dots + v_{n-1}x^{n-1} $$
					</p>

					<p>
						Then we notice that $a_k = f(\om_n^{-k})$, and we want to find $a_k$ for all $0 \leq k < n$, which is a sampling problem.
					</p>

					<p>
						Using the strategies from sampling quickly, we'll once again define
					</p>

					<p>
						$$\begin{align}v_e(x) &= v_0 + v_2x^2 + \dots + v_{n-2}x^{n-2} \\v_o(x) &= v_1x + v_3x^3 + \dots + v_{n-1}x^{n-1} \\\end{align}$$
					</p>

					<p>
						It should come as no surprise that if $m = \frac n2$, $v(\om_n^{-k}) = v_e(\om_m^{-k}) + \om_n^{-k}v_o(\om_m^{-k})$, and we can verify this:
					</p>

					<p>
						$$\begin{align}&\phantom{=.} v_e(\om_m^{-k}) + \om_n^{-k}v_o(\om_m^{-k}) \\&=\mathbb{TODO}\end{align}$$
					</p>

					<p>
						Consequently, we also have the useful formula:
					</p>

					<p>
						$$\begin{align}v(\om_n^{-k})   &= f_e(\om^{-k}_m) + \om^{-k}_n f_o(\om^{-k}_m) \\v(\om_n^{-k+m}) &= f_e(\om^{-k}_m) - \om^{-k}_nf_o(\om^{-k}_m)\end{align}$$
					</p>

					<p>
						and so we also have a very similar algorithm for interpolating quickly:
					</p>

					<div class="block">
						<div class="block-heading">Interpolating Algorithm</div>

					<p>
						TODO
					</p>
					</div>
				</div>
			</div>

			<div id="toc10" class="section">
				<div class="heading">Complex Numbers</div>
				<div class="subsection">

					<p>
						Now that we know how to sample and interpolate quickly using primitive $n$-th roots of unity, we need to find a number system where these primitive roots of unity exist.
					</p>

					<p>
						For some given $n$, we want to find some $\om_n$ that satisfies $\om_n^n = 1$. This is equivalent to finding the solutions to the polynomial $x^n = 1$. We know from the Fundamental Theorem of Algebra that every polynomial of degree $n$ has exactly $n$ solutions, which is a good sign. We're also hoping that at least one of these solutions gives us a <i>primitive</i> $n$-th root of unity.
					</p>

					<p>
						Using the Fundamental Theorem of Algebra on the polynomial $x^4 = 1$, we expect $4$ solutions for $x$, but we know that there are only two possible: $1$ and $-1$, so where are the other solutions?
					</p>

					<p>
						It turns out the Fundamental Theorem of Algebra only works if we extend the regular numbers. Let's introduce a new number $i$ which is equal to $\sqrt{-1}$. Using regular numbers, the square root of any negative number doesn't exist, but allowing them to exist gives us interesting and useful properties.
					</p>

					<p>
						For one, now we have $4$ solutions to the polynomial $x^4 = 1$. The solutions are $1$, $-1$, $i$, and $-i$. To verify this, we first note that since by definition $i = \sqrt{-1}, i^2 = -1$. Now, to verify that $i^4 = 1$, we show:
					</p>

					<p>
						$$i^4 = (i^2)^2 = (-1)^2 = 1$$
					</p>

					<p>
						Next, we verify that $(-i)^4 = 1$:
					</p>

					<p>
						$$(-i)^4 = (-1)^4(i)^4 = (1)(1) = 1$$
					</p>

					<p>
						In particular, $i$ is a primitive $4$-th root of unity since for all $0 < k < 4$, $i^k \neq 1$. We can verify these manually: $i^1 = i$, $i^2 = -1$, and $i^3 = (i^2)(i) = -i$. As a bonus, $-i$ is also a primitive $4$-th root of unity.
					</p>

					<p>
						We can also mix regular numbers with multiples of $i$. For example, we can have the number $5 + 3i$ or $2.5 - \sqrt2 i$. These numbers are called <b>complex numbers</b>. This representation is important since all numbers involving $i$ in any way can be expresseed by $a + bi$ where $a$ and $b$ are regular numbers. For example, $7^{3i} \approx 0.9024 - 0.431i$.
					</p>

					<p>
						In the complex numbers, we can guarantee $n$ solutions to the polynomial $x^n = 1$.
					</p>

					<p>
						For example, the $3$ solutions to $x^3 = 1$ are $1$, $\left(-\frac12 + \frac{\sqrt3}2i\right)$, and $\left(-\frac12 - \frac{\sqrt3}2i\right)$. We can verify that $\left(-\frac12 + \frac{\sqrt3}2i\right)^3 = 1$ by expanding using the Binomial Theorem:
					</p>

					<p>
						$$\begin{align}&\phantom{=|} \left(-\frac12 + \frac{\sqrt3}2i\right)^3 \\&= \left(-\frac 12\right)^3 + 3\left(-\frac 12\right)^2\left(\frac{\sqrt3}{2}i\right) + 3\left(-\frac 12\right)\left(\frac{\sqrt3}{2}i\right)^2 + \left(\frac{\sqrt3}2i\right)^3 \\&= \left(-\frac 12\right)^3  + 3\left(-\frac12\right)^2\left(\frac{\sqrt3}2\right)i +3\left(-\frac12\right)\left(\frac{\sqrt3}{2}\right)^2i^2 + \left(\frac{\sqrt3}{2}\right)^3i^3 \\&= -\frac 18 + 3\left(\frac14\right)\left(\frac{\sqrt3}2\right)i +3\left(-\frac12\right)\left(\frac 34\right)(-1) + \left(\frac{3\sqrt3}{8}\right)(-i) \\&= -\frac18 + \frac{3\sqrt3}8i + \frac{9}{8} - \frac{3\sqrt3}8i \\&= -\frac18 + \frac98 \\&= 1\end{align}$$
					</p>

					<p>
						The verification that $\left(-\frac12 - \frac{\sqrt3}2i\right)^3 = 1$ works pretty similarly. Also, both $-\frac12 + \frac{\sqrt3}2i$ and $-\frac12 - \frac{\sqrt3}2i$ are primitive third roots of unity.
					</p>

					<p>
						In general, for all $n > 0$, we can find $n$ solutions to $x^n = 1$ and at least one of the solutions is a primitive $n$-th root of unity. To find the solutions and the primitive $n$-th root of unity, we can use the following theorem:
					</p>

					<div class="block">
						<div class="block-heading">Theorem 4 - Complex Roots of Unity</div>

					<p>
						For all integers $n > 0$, the solutions to the polynomial $x^n = 1$ are
					</p>

					<p>
						$$\cos \theta + i \sin\theta $$
					</p>

					<p>
						For all angles $\theta$ (in radians)
					</p>

					<p>
						$$0, \frac{2\pi}{n}, \frac{4\pi}n, \frac{6\pi}n, \dots, \frac{(n-1)2\pi}n$$
					</p>

					<p>
						In particular, for $\theta = \frac{2\pi}{n}$, ie. the number $\cos\left(\frac{2\pi}{n}\right) + i\sin\left(\frac{2\pi}{n}\right)$ is a primitive $n$-th root of unity.
					</p>

<a href="proof4.html">Proof</a>
					</div>
				</div>
			</div>

			<div id="toc11" class="section">
				<div class="heading">Implementation - Complex Numbers</div>
				<div class="subsection">

					<p>
						Now that we have all the tools we need, let's look at how to construct the actual code to perform the polynomial multiplication. Here's a quick recap of how we'll handle the polynomials:
					</p>

					<div class="block">
						<div class="block-heading">Summary of the Full Algorithm</div>

					<p>
						Let $f(x) = a_0 + \dots + a_nx^n$ be a polynomial of degree $n$ and $g(x) = b_0 + \dots + b_mx^m$ be a polynomial of degree $m$. We wish to calculate $h(x) = f(x)g(x) = c_0 + \dots + c_{n + m}x^{n + m}$.
					</p>

<ol>

<li>Let $N$ be the smallest power of 2 that is greater or equal to $\max(n - 1, m - 1)$. We upgrade the degrees of $f(x)$ and $g(x)$ to degree $2N - 1$ by padding the higher degrees with zeroes.</li>

<li>Choose $\om = \cos\left(\frac{2\pi}{2N}\right) + i\sin\left(\frac{2\pi}{2N}\right)$ to be the primitive $2N$-th root of unity.</li>

<li>Using the above recursive strategy, sample both $f(x)$ and $g(x)$ at the roots of unity, calculating $f(1), f(\om), f(\om^2), \dots, f(\om^{N - 1})$ and $g(1), g(\om), g(\om^2), \dots, g(\om^{N - 1})$.</li>

<li>Calculate $h(1) = f(1)g(1),\ \ h(\om) = f(\om)g(\om),\ \ h(\om^2) = f(\om^2)g(\om^2), \dots, h(\om^{N - 1}) = f(\om^{N - 1})g(\om^{N - 1})$</li>

<li>Using the above strategy, interpolate the samples for $h(1), \dots, h(\om^{N - 1})$ to recover $h(x) = c_0 + \dots + c_{2N - 1}x^{2N - 1}$</li>

<li>Remove the extra zeroes from the end of the polynomial to get $h(x) = c_0 + \dots c_{n + m}x^{n + m}$</li>

</ol>
					</div>
				</div>
			</div>

			<div id="toc12" class="section">
				<div class="heading">The Integers Modulo A Prime Number</div>
				<div class="subsection">

					<p>
						In the previous section, we saw a number system where $n$-th roots of unity exist by extending the regular numbers to include $i$, the square root of $-1$. In this section, we'll instead use <i>the integers modulo $p$</i>, number system with $n$-th roots of unity by restricting the integers.
					</p>

					<p>
						To explain this system,  let's look at a real-wrold example. In military the 24 hours in a day are labelled from $0$ to $23$, where Hour $0$ is midnight. If the time right now is Hour $19$, then $9$ hours later, it'll be Hour $4$ (on the next day). We know it'll be Hour $4$ because $19 + 9 = 28$ but there are only $24$ hours in a day, so we subtract $24$ hours and we know that it must be Hour $4$ on the next day. Using similar logic, if it's Hour $3$, then $10$ hours ago, it was $17$ (on the previous day).
					</p>

					<p>
						The general strategy when adding or subtracting hours together is add them regularly like numbers, then add or subtract multiples of $24$ until the number is between $0$ and $23$ inclusive. The integers modulo $24$ work the exact same way, except we also allow the multiplication of numbers. With multiplication, we also multiply the numbers normally, but we make sure to add or subtract mutiples of $24$ until the number is between $0$ and $23$ inclusive. For example, $6 \times 7 = 18$ since $6 \times 7$ is regularly $42$, but it's not between $0$ and $23$, so we subtract $24$ to get $18$, which is between $0$ and $23$.
					</p>

					<p>
						In general for all $n > 0$, the integers modulo $n$ is a number system where we apply the rules above, except with any number $n$. In particular, we do every math operation as usual except if the number isn't between $0$ and $n - 1$ inclusive, we add or subtract a multiple of $n$ so that it is. Also, since operations work differently in the integers modulo $n$ than in regular numbers, we should use the triple equals $\equiv$ to show that we aren't using regular numbers and $(\text{mod } n)$ to show which $n$ we are using. For example, we write that $6 \times 7 \equiv 18 \pmod{24}$ to communicate the example above: in the integers modulo $24$, $6$ times $7$ is $18$.
					</p>

					<p>
						In particular, if our choice of $n$ is a prime number, then we can also call the system "the integers modulo $p$". The reason why we give a different name for when $n$ is a prime number is because a lot of interesting properties arise. If $n = 7$, let's look at the exponents of each number:
					</p>

<style> table{ border-collapse: collapse; margin: 0px auto; } th, td{ padding: 5px 10px 5px 10px; border: 1px solid black; text-align: center; } .th2 { background-color: #EED3AA; } th { font-weight: normal; background-color: #F3DEBE; } </style>

<table>

<tr>

<td style="border-width: 0px;"></td>

<th class="th2" colspan="7">$b$</td>

</tr>

<tr>

<th class="th2" rowspan="7">$a$</td>

<th>$a^b$</td>

<th>1</th>

<th>2</th>

<th>3</th>

<th>4</th>

<th>5</th>

<th>6</th>

</tr>

<tr>

<th>1</th>

<td>1</td>

<td>1</td>

<td>1</td>

<td>1</td>

<td>1</td>

<td>1</td>

</tr>

<tr>

<th>2</th>

<td>2</td>

<td>4</td>

<td>1</td>

<td>2</td>

<td>4</td>

<td>1</td>

</tr>

<tr>

<th>3</th>

<td>3</td>

<td>2</td>

<td>6</td>

<td>4</td>

<td>5</td>

<td>1</td>

</tr>

<tr>

<th>4</th>

<td>4</td>

<td>2</td>

<td>1</td>

<td>4</td>

<td>2</td>

<td>1</td>

</tr>

<tr>

<th>5</th>

<td>5</td>

<td>4</td>

<td>6</td>

<td>2</td>

<td>3</td>

<td>1</td>

</tr>

<tr>

<th>6</th>

<td>6</td>

<td>1</td>

<td>6</td>

<td>1</td>

<td>6</td>

<td>1</td>

</tr>

</table>

					<p>
						The way we should read this table is that excluding the darker header cells, the $a$-th row and $b$-th column gives $a^b \pmod 7$.
					</p>

					<p>
						There are some observations we can make from the table:
					</p>

<ol>

<li>There are no zeroes</li>

<li>The sixth column is filled with ones</li>

<li>The third and fifth column cycle through all the numbers from $1$ to $6$</li>

</ol>

					<p>
						Observation 2 tells us that all numbers from $1$ to $6$ to the sixth power is $1$, which means these numbers are all sixth roots of unity.
					</p>

					<p>
						Observation 3 tells us that $3$ and $5$ are primitive sixth roots of unity since for all $0 < k < 6$, $3^k$ and $5^k$ aren't equal to $1$.
					</p>

					<p>
						In fact, similar results are guaranteed for the integers modulo $p$, where $p$ is any prime number.
					</p>

					<div class="block">
						<div class="block-heading">Theorem 5 - Roots of Unity in the Integers Modulo p</div>

<ol>

<li>In the integers modulo $p$, where $p$ is any prime number, for all $0 < a < p$, $a$ is a $(p - 1)$-th root of unity.</li>

<li>There's at least one number $0 < b < p$ such that $b$ is a <i>primitive</i> $(p - 1)$-th root of unity.</li>

</ol>

<a href="proof5.html">Proof</a>
					</div>

					<p>
						Unfortunately, unlike with the complex numbers, there's no easy way to find a primitive $(p - 1)$-th root of unity. There is a more involved way, but we'll come back to this later.
					</p>

					<p>
						In the previous sections, we found that sampling and interpolating is best done when the input size is a power of $2$ and that we use $2^k$-th roots of unity. By the theorem above, a prime number $p$ guarnatees a primitive $(p - 1)$-th root of unity for any prime number, so if we find a prime number of the form $2^k + 1$, we can get a primitve $2^k$-th root of unity, which is what we need.
					</p>

					<p>
						However, we currently know a total of $5$ prime numbers of the $2^k + 1$: $3$, $5$, $17$, $257$, and $65537$. These are far too small since problems requiring the multiplication of polynomials in $O(N \log N)$ will often have the degree be at least $100\ 000$.
					</p>

					<p>
						To get around this, we relax the requirement to have a prime number be the form of $c \cdot 2^k + 1$ where $c$ is any odd integer. There are many primes of this form, but for this article, we'll use $p = 3 \cdot 2^{30} + 1 = 3221225473$. Since $p < 2^{32}$, this will allow us to use unsigned 64-bit integers without the possibility of integer overflow.
					</p>

					<p>
						However, we're guaranteed a primitive $(p - 1)$-th root of unity, and in this case, $p - 1$ is $3 \cdot 2^{30}$, but what we really wanted was a $2^{30}$-th root of unity. Thankfully, there's an easy way to recover the root of unity we want.
					</p>

					<div class="block">
						<div class="block-heading">Theorem 6 - Converting Primitive Roots of Unity</div>

					<p>
						Let $p$ be a prime of the form $c \cdot 2^k + 1$ and $\om$ be a primitive $(p - 1)$-th root of unity in the integers modulo $p$.
					</p>

					<p>
						$\om^c$ is a primitive $2^k$-th root of unity in the integers modulo $p$.
					</p>

<a href="proof6.html">Proof</a>
					</div>
				</div>
			</div>

		</div>
	</body>
</html>