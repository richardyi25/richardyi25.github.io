<html lang="en">
	<head>
		<meta charset="UTF-8">
		<title>A Gentle Dive into FFT</title>
		<link rel="stylesheet" href="prism.css">
		<link rel="stylesheet" href="../style.css">
		<script type="text/x-mathjax-config">
			MathJax.Hub.Config({
				tex2jax: {
					inlineMath: [['$','$']],
					displayMath: [['$$','$$']],
					processEscapes: true
				}
			});
		</script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
		<script src="prism.js"></script>
	</head>

	<body>
		<div id="title">A Gentle Dive into FFT</div>

		<div id="preamble">
				$$
				\newcommand{\om}{\omega}
				$$
		</div>

		<div id="warning">
			<div class="subheading">Warning: This article is not finished</div>
			This article is still being written and edited. There are most likely many mistakes and typos.
		</div>

		<div id="toc">
			<div class="heading">Table of Contents</div>
			<ul>
				<li><a href="#toc0">Introduction</a></li>
				<li><a href="#toc1">Multiplying Polynomials</a></li>
				<li><a href="#toc2">Sampling and Interpolating</a></li>
				<li><a href="#toc3">Speedup Overview</a></li>
				<li><a href="#toc4">Primitive Roots of Unity</a></li>
				<li><a href="#toc5">Sampling Quickly</a></li>
				<li><a href="#toc6">Reducing Interpolating to Sampling</a></li>
				<li><a href="#toc7">Interpolating Quickly</a></li>
			</ul>
		</div>

		<div id="main">

			<div id="toc0" class="section">
				<div class="heading">Introduction</div>
				<div class="subsection">

					<p>
						In competitive programming, the Fast Fourier Transform is a technique that speeds up polynomial multiplication from $O(n^2)$ to $O(n \log n)$. In this article, we will explore the basic concepts behind this speedup and its implementation and applications.
					</p>
				</div>
			</div>

			<div id="toc1" class="section">
				<div class="heading">Multiplying Polynomials</div>
				<div class="subsection">

					<p>
						First, let's recap what a polynomial is:
					</p>

					<div class="block">
						<div class="block-heading">Defintion - Polynomial</div>

					<p>
						A polynomial $f(x)$ of degree $n$ is defined as $$f(x) = a_0 + a_1x + a_2x^2 + \dots + a_nx^n$$
					</p>

					<p>
						where $a_0, \dots, a_n$ are numbers.
					</p>
					</div>

					<p>
						It's common to include the restriction $a_n \neq 0$, but we won't. This allows us to "upgrade" polynomials to a higher degree by adding coefficients with value $0$.
					</p>

					<p>
						For example, if $f(x) = a_0 + a_1x + \dots + a_nx^n$ is a polynomial of degree $n$, we can "upgrade" it to a polynomial of degree $n + k$ if we take $f(x)$ to be $a_0 + \dots + a_nx^n + 0a_{n+1} + \dots + 0x^{n+k}$.
					</p>

					<p>
						We can multiply polynomials to get a new polynomial. Suppose $f(x) = a_0 + a_1 + \dots + a_nx^n$ and $g(x) = b_0 + b_1 + \dots + b_nx^n$ are both polynomials of degree $n$. Let $h(x) = f(x)g(x)$ be their product. We can calculate $h(x)$ by distributing and collecting the terms:
					</p>

					<p>
						$$\begin{align}h(x) &= f(x)g(x) \\     &=(a_0 + a_1x + \dots + a_nx^n)(b_0 + b_1x + \dots + b_nx^n) \\     &= \sum_{i = 0}^n \sum_{j = 0}^n a_ib_jx^{i+j}\end{align}$$
					</p>

					<p>
						The product $h(x) = f(x)g(x) = c_0 + c_1x + \dots + c_{2n}x^{2n}$ is a polynomial of degree $2n$. We can find the $k$-th coefficient $c_k$ for all $0 \leq k \leq 2n$ by adding all $a_ib_j$ such that $i + j = k$. To do this, we loop thourgh all $i$ from 0 to $k$ inclusive and set $j = k - i$.
					</p>

					<div class="block">
						<div class="block-heading">Polynomial Mutliplciation Formula</div>

					<p>
						If
					</p>

					<p>
						$$\begin{align}f(x) &= a_0 + a_1x + \dots + a_nx^n \\g(x) &= b_0 + b_1x + \dots + a_nx^n \\h(x) = f(x)g(x) &= c_0 + c_1x + \dots + c_{2n}x^{2n}\end{align}$$
					</p>

					<p>
						then for all $0 \leq k \leq 2n$,
					</p>

					<p>
						$$ c_k = \sum_{i = 0}^k a_ib_{k - i} $$
					</p>
					</div>

					<p>
						Note that this formula takes $O(n^2)$ time to compute $c_k$ for all $0 \leq k \leq 2n$, despite it only being $O(n)$ space of information. There seems to be a neat structure to the computation, so there's probably room for improvement by reusing calculations. This is where the Fast Fourier Transform comes in.
					</p>
				</div>
			</div>

			<div id="toc2" class="section">
				<div class="heading">Sampling and Interpolating</div>
				<div class="subsection">

					<p>
						A polynomial $f(x) = a_0 + \dots + a_nx^n$ can be represented by only its coefficients $a_0, \dots, a_n$. However, if we know its value at enough points, we can also determine the coefficients of the polynomial.
					</p>

					<div class="block">
						<div class="block-heading">Theorem - Uniqueness of Interpolation</div>

					<p>
						Let $f(x) = a_0 + \dots + a_nx^n$ be a polynomial with degree $n$ whose coefficients $a_0, \dots, a_n$ are unknown. For any choice of $n + 1$ distinct numbers $s_0, \dots, s_n$, if we know $f(s_0), \dots, f(s_n)$, then we can uniquely determine $a_0, \dots, a_n$.
					</p>
					</div>

					<p>
						Let's call the choice of distinct numbers $s_0, \dots, s_n$ <i>sampling points</i> and the values of $f(s_0), \dots f(s_n)$ <i>samples</i>. Note that while the samples uniquely determine the coefficients, the samples themselves aren't unique because any choice of distinct sampling points will work. Any polynomial that satisfies the samples is said to <i>interpolate</i> the samples.
					</p>

					<p>
						We'll call the process of calculating samples from the polynomial in coefficient form <i>sampling</i> and the process of determining the coefficients from samples <i>interpolating</i>.
					</p>

					<p>
						We can give a simplified proof sketch for the theorem. Say we have some polynomials $f(x)$ and $g(x)$ of degree $n$ and for $0 \leq i \leq n$, $f(s_i) = g(s_i)$, that is, they have the same value at $n + 1$ points. If we prove that $f(x)$ is neccesarily equal to $g(x)$, then values at $n + 1$ points will uniquely determine a polynomial of degree $n$.
					</p>

					<p>
						Consider the polynomial $h(x) = f(x) - g(x)$. Since $f(x)$ and $g(x)$ have degree $n$, $h(x)$ has at most degree $n$, and by the Fundamental Theorem of Algebra, if $h(x)$ is not $0$ for every value of $x$, then it has at most $n$ roots.
					</p>

					<p>
						However, $0 \leq i \leq n$, $f(s_i) = g(s_i) \implies f(s_i) - g(s_i) = h(s_i) = 0$, so $h(x)$ has $n + 1$ roots. Therefore, the only possbility is that $h(x) = 0$, which means $f(x) = g(x)$, as required.
					</p>
				</div>
			</div>

			<div id="toc3" class="section">
				<div class="heading">Speedup Overview</div>
				<div class="subsection">

					<p>
						For the sake of later convenience, we'll talk about multiplying polynomials of degree $n - 1$ from now on.
					</p>

					<p>
						Let $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$ and $g(x) = b_0 + \dots + b_{n-1}x^{n-1}$ be polynomials of degree $n - 1$. Instead of multiplying them directly, we'll first sample both $f(x)$ and $g(x)$ at sample points $s_0, \dots, s_{2n - 1}$, calculating $f(s_0), \dots, f(s_{2n - 1})$ as well as $g(s_0), \dots, g(s_{2n - 1})$.
					</p>

					<p>
						Then we'll pointwise multiply the samples, calculating $f(s_0)g(s_0), \dots f(s_{2n - 1})g(s_{2n - 1})$. The theorem from the previous section tells us that this is enough to recover the coefficients of $f(x)g(x)$, since we have $2n$ samples and $f(x)g(x)$ is of degree $2n - 2$. Once we do that, we've calculated $f(x)g(x)$.
					</p>

					<p>
						If we can quickly sample and interpolate polynomials, then we can quickly multiply polynomials since the pointwise multiplication step only takes $O(N)$ time.
					</p>
				</div>
			</div>

			<div id="toc4" class="section">
				<div class="heading">Primitive Roots of Unity</div>
				<div class="subsection">

					<p>
						We have the luxury of picking whichever $2n$ sample points $s_0, \dots s_{2n - 1}$ we want, but if we want both sampling and interpolation to be fast, we better pick sample points that allow us to reuse calculations.
					</p>

					<p>
						The type of number that will allow us to do this is the primitive roots of unity.
					</p>

					<div class="block">
						<div class="block-heading">Definition - Roots of Unity and Primitivity</div>

					<p>
						Let $n$ be a positive integer. A number $\om_n$ is said to be an $n$-th root of unity if $\om_n^n =1 $.
					</p>

					<p>
						In addition, a $n$-th root of unity $\om_n$ is said to be <i>primitive</i> if for all $0 < k < n$, $\om_n^k \neq 1$.
					</p>
					</div>

					<p>
						In the real numbers, only $1$ and $-1$ could possibly be roots of unity, but not primitive $n$-th roots of unity for $n > 2$, so we'll have to use a different number system. If you're familiar with complex numbers or the integers modulo a prime number, you might know examples of primitive roots of unity. However, we only need to work with the above definition to be able to prove these important properties:
					</p>

					<div class="block">
						<div class="block-heading">Properties of Primitive Roots of Unity</div>

					<p>
						Let $n$ be an even number and $\om_n$ be a primitive $n$-th root of unity and $m = \frac n2$.
					</p>

<ol>

<li>For all $0 < k < n$, the values of $\om_n^k$ are distinct</li>

<li>$\om_{n}^m = -1$</li>

<li>For any $k$, $(\om_n^k)^2 = (\om_n^{m + k})^2 = \om_m^k$ where $\om_m$ is a primitive $m$-th root of unity</li>

<li>

					<p>
						For all $0 < k < n$, $\om_n^0 + \om_n^k + \om_n^{2k} + \dots + \om_n^{(n-1)k} = 0$.
					</p>

</li>

</ol>
					</div>

					<p>
						For the rest of the article, we'll keep the convention of $m = \frac n2$. If you're not interested in proofs, you can skip to the next section.
					</p>

<div class="subheading">Proof of #1</div>

					<p>
						Suppose the statement isn't true: that there exist $k_1$ and $k_2$ such that $0 < k_1 < k_2 < n$ and $\om_m^{k_1} = \om_m^{k_2}$. If we divide both sides by $\om_n^{k_1}$, we then get $\om_n^{k_2 - k_1} = 1$. But since $0 < k_1 < k_2 < n$, we have $0 < k_2 - k_1 < n$, and by the definition of primitivity, $\om_n^{k_2 - k_1}$ can't be $1$. We reach a contradiction so the values of $\om_n^k$ must indeed be distinct.
					</p>

<div class="subheading">Proof of #2</div>

					<p>
						Since $(\om_n^m)^2 = \om_n^2m = \om_n^n = 1$, we know that $\om_n^m$ must be either $-1$ or $1$. However, since $\om_n$ is primitive and $0 < m < n$, $\om_n^m \neq 1$, so it must be $-1$.
					</p>

<div class="subheading">Proof of #3</div>

					<p>
						We first prove that $\om_n^2$ is a primitive $m$-th root of unity by definition. $\om_n^2$ is a $m$-th root of unity since $(\om_n^2)^m = \om_n^{2m} = \om_n^n = 1$. It is primitive since for all $0 < k < m$, $(\om_n^2)^k = \om_n^{2k}$. Since $0 < k < m$, $0 < 2k < 2m = n$, so $(\om_n^2)^k \neq 1$.
					</p>

					<p>
						As a result, we also get the property that $(\om^k_n)^2 = (\om^2_n)^k = \om_m^k$. Also, by combining results above, we have $(\om_n^{m + k})^2 = (\om_n^m\om_n^k)^2 = (\om_n^m)^2(\om_n^k)^2 = (-1)^2(\om_n^k)^2 = \om_m^k$.
					</p>

<div class="subheading">Proof of #4</div>

					<p>
						Let $c$ be the value of the sum $\om_n^0 + \om_n^k+ \dots + \om_n^{(n-1)k}$. We want to prove that $c=0$.
					</p>

					<p>
						$$\begin{align}c &= \om_n^0 + \om_n^k+ \dots + \om_n^{(n-1)k}\end{align}$$
					</p>

					<p>
						Let's mutiply both sides by $1 - \om_n^k$:
					</p>

					<p>
						$$\require{cancel}\begin{align}c(1 -\om_n^k) &= (\om_n^0 + \om_n^k + \dots + \om_n^{(n-1)k})(1-\om_n^k) \\c(1-\om_n^k)  &= (\om_n^0 + \om_n^k + \dots + \om_n^{(n-1)k})-\om_n^k(\om_n^0 + \om_n^k + \dots + \om_n^{(n-1)k}) \\c(1-\om_n^k)  &= \om_n^0+\om_n^k+\dots+\om_n^{(n-1)k}-\om_n^k-\om_n^{2k}-\dots-\om_n^{nk} \\c(1-\om_n^k)  &= \om_n^0+\cancel{\om_n^k}+\dots+\cancel{\om_n^{(n-1)k}}-\cancel{\om_n^k}-\cancel{\om_n^{2k}}-\dots-\om_n^{nk} \\c(1-\om_n^k)  &= \om_n^0-\om_n^{nk} \\c(1-\om_n^k)  &= 1-(\om_n^{n})^k \\c(1-\om_n^k)  &= 1-(1)^k \\c(1-\om_n^k)  &= 0\end{align}$$
					</p>

					<p>
						Since $c(1-\om_n^k) = 0$, at least one of $c$ and $(1-\om_n^k)$ must be $0$.
					</p>

					<p>
						But since $0 < k < n$, by definition we have $\om_n^k \neq 1 \implies 1 - \om_n^k \neq 0$, so $c$ must be $0$.
					</p>
				</div>
			</div>

			<div id="toc5" class="section">
				<div class="heading">Sampling Quickly</div>
				<div class="subsection">

					<p>
						We can now solve the problem of finding $n$ samples from a polynomial of degree $n - 1$.
					</p>

					<p>
						Let's recap what the problem is
					</p>

					<div class="block">
						<div class="block-heading">Sampling Problem Statement</div>

					<p>
						Given $a_0, \dots, a_{n-1}$ which determines $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$, and a choice of $n$ sampling points $s_0, s_1, \dots, s_{n-1}$, we wish to find the samples
					</p>

					<p>
						$$ f(s_0), f(s_1), \dots, f(s_{n-1}) $$
					</p>

					<p>
						where
					</p>

					<p>
						$$\begin{align}f(s_0) &= a_0 + a_1s_0 + a_2s_0^2 + \dots + a_{n-1}s_0^{n-1} \\f(s_1) &= a_1 + a_1s_1 + a_2s_1^2 + \dots + a_{n-1}s_1^{n-1} \\&\phantom{$a_1+a_1s_1+a_2$}     \vdots \\f(s_{n-1}) &= a_1 + a_1s_{n-1} + a_2s_{n-1}^2 + \dots + a_{n-1}s_{n-1}^{n-1} \\\end{align}$$
					</p>
					</div>

					<p>
						We can easily evaluate the $n$ samples in $O(n^2)$ time since it takes $O(n)$ time to calculate a single sample and we have $O(n)$ samples to calculate. In order to speed this up to $O(n \log n)$, we'll have to take advantage of the properties of the primitive roots of unity.
					</p>

					<p>
						Let $n$ be an even number and $m = \frac n2$. Let $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$ be an $n - 1$ degree polyomial. We define two $n - 1$ degree polynomials, $f_e$ keeping only the coefficients at even degree and $f_o$ keeping only the coefficients at odd degree:
					</p>

					<p>
						$$\begin{align}f_e(x) &= a_0 + a_2x + a_4x^2 + \dots+ a_{n-2}x^{m-1}f_o(x)&=a_1+a_3x + a_5x^2 + \dots + a_{n-1}x^{m-1}\end{align}$$
					</p>

					<p>
						Now let $\om_n$ be a primitive $n$-th root of unity. We'll drop the subscript $_n$ for now for convenience. We can conveniently evaluate $f(\om^k)$ from just $f_e(\om^{2k})$ and $f_o(\om^{2k})$:
					</p>

					<p>
						$$\begin{align}f_e(\om^{2k}) + \om^kf_o(\om^{2k})  &= \left(a_0 + a_2\om^{2k} + \dots + a_{n-2}\om^{2k(m - 1)}\right)+\om^k\left(a_1+a_3\om^{2k}+\dots+a_{n-1}\om^{2k(m-1)}\right) \\  &= \left(a_0+a_2\om^{2k}+\dots+a_{n-2}\om^{(n-2)k}\right)+\left(a_1\om^k+a_3\om^{3k}+\dots+a_{n-1}\om^{(n-1)k}\right) \\  &= a_0+a_1\om^k+a_2\om^{2k}+a_3\om^{3k}+\dots+a_{n-2}\om^{(n-2)k}+a_{n-1}\om^{(n-1)k} \\  &= f(\om^k)\end{align}$$
					</p>

					<p>
						Let's bring the subscript $_n$ back so we can manipulate the result that we found. If $\om_n$ is a primitive $n$-th root of unity and $m = \frac n2$, then
					</p>

					<p>
						$$\begin{align}f(\om_n^k) &= f_e(\om_n^{2k}) + \om_n^k f_o(\om_n^{2k}) \\           &= f_e((\om_n^k)^2) + \om_n^kf_o((\om_n^k)^2) \\           &= f_e(\om_m^k)+\om_n^kf_o(\om_m^k)\end{align}$$
					</p>

					<p>
						This formula works for all $0 \leq k < n$, but if we restrict $k$ to the range $0 \leq k < m$ and consider both $k$ and $k + m$, we find a very special pattern:
					</p>

					<p>
						$$ f(\om_n^k) = f_e(\om_m^k)+\om_n^kf_o(\om_m^k) $$
					</p>

					<p>
						as expected, but
					</p>

					<p>
						$$\begin{align}f(\om_n^{k + m}) &= f_e(\om_n^{k + m})+\om_n^{k + m}f_o(\om_m^{k + m}) \\                 &= f_e(\om_m^k\om_m^m) + \om_n^n \om_n^k f_o(\om_m^k\om_m^m) \\                 &= f_e(\om_m^k) - \om_n^k f_o(\om_m^k)\end{align}$$
					</p>

					<p>
						To recap, we've found that
					</p>

					<div class="block">
						<div class="block-heading">Sampling Reduction Formula</div>

					<p>
						If $n$ is an even number, $m = \frac n2$, and
					</p>

					<p>
						$$\begin{align}f(x)   &= a_0 + a_1x + a_2x^2+ \dots + a_{n-1}x^{n-1} \\f_e(x) &= a_0 + a_2x + a_4x^2 + \dots+ a_{n -2}x^{m-1} \\f_o(x) &= a_1+a_3x + a_5x^2 + \dots + a_{n-1}x^{m-1}\end{align}$$
					</p>

					<p>
						and $\om_n$ is a primitive $n$-th root of unity, then for all $0 \leq k < m$,
					</p>

					<p>
						$$\begin{align}f(\om_n^k)     &= f_e(\om^k_m) + \om^k_n f_o(\om^k_m) \\f(\om_n^{k+m}) &= f_e(\om^k_m) - \om^k_nf_o(\om^k_m)\end{align}$$
					</p>
					</div>

					<p>
						This is an extremely important formula. This means that if we need to sample $f(x)$ at $\om_{2n}^0, \om_{2n}^1, \dots \om_{2n}^{2n-1}$, we can reduce this into the problem of sampling $f_e(x)$ and $f_o(x)$ at $\om_n^0, \om_n^1, \dots \om_n^{n-1}$ with a cost of $O(n)$ steps.
					</p>

					<p>
						At first glance, this doesn't help at all. In order to calculate $2n$ samples, we need to calculate $n$ samples for each of the functions $f_e$ and $f_o$, which is still $2n$ samples in total.
					</p>

					<p>
						What if we kept using this formula over and over again? Let $n$ be a power of two, say $n = 2^k$. Suppose we have a polynomial of degree $n - 1$ and want to find $n$ samples. With a cost of $O(n)$ steps, we can reduce the problem into finding $\frac{n}{2}$ samples for $2$ polynomials of degree $\frac{n}{2} - 1$. If we apply the formula to each of the smaller polynomials, then with a cost of $2 \times \frac{n}{2} = O(n)$, we can reduce the problem further to finding $\frac{n}{4}$ samples for $4$ polynomials of degree $\frac{n}{4} - 1$.
					</p>

					<p>
						Eventually, after $k$ iterations of this, with each iteration incurring a cost of $O(n)$ steps, the problem is reduced to finding one sample for $n$ polynomials each of degree $0$. This is now trivial to do since a sample of a polynomial $f(x) = a_0$ of degree $0$ is just $a_0$, so this step takes $O(n)$ time. In total, since $n = 2^k$, then $k = \log n$, so we spent $O(n) \times O(\log n) = O(n \log n)$ time reducing the problem to the trivial form, and $O(n)$ time solving the trivial form. Therefore, we've found a way to take $n$ samples in just $O(n)$ time.
					</p>

					<div class="block">
						<div class="block-heading">Sampling Algorithm</div>

					<p>
						Let $n$ be a power of $2$, $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$ be a polynomial of degree $n - 1$ and $\om_{n}$ be a primitive $n$-th root of unity.
					</p>

					<p>
						To calculate $n$ samples $f(\om_n^0), f(\om_n^1), \dots, f(\om_n^{n-1})$:
					</p>

<ul>

<li>If $n = 1$, then the only sample we need is $f(\om_1^0) = f(1) = a_0$.</li>

<li>

					<p>
						Otherwise, let $m = \frac n2$ and $$\begin{align}f_e(x) &= a_0 + a_2x + a_4x^2 + \dots + a_{n-1}x^{m-1}\\f_o(x)&=a_1+a_3x+a_5x^2+\dots+a_nx^{m-1}\end{align}$$
					</p>

					<p>
						We recursively apply this algorithm on $f_e(x)$ and $f_o(x)$ to find $f_e(\om_{m}^0), f_e(\om_{m}^1), \dots, f_e(\om_{m}^{m - 1})$ and $f_o(\om_{m}^0), f_o(\om_{m}^1), \dots, f_o(\om_{m}^{m - 1})$.
					</p>

					<p>
						From these samples, we can calculuate $f(\om_n^0), f(\om_n^1), \dots, f(\om_n^{n-1})$:
					</p>

					<p>
						For all $0 \leq k < m$,
					</p>

					<p>
						$$\begin{align}f(\om_n^k)     &= f_e(\om^k_m) + \om^kf_o(\om^k_m) \\f(\om_n^{k+m}) &= f_e(\om^k_m) - \om^kf_o(\om^k_m)\end{align}$$
					</p>

</li>

</ul>
					</div>

					<p>
						Of course, when we sample a polynomial, it's not always going to have a degree that's one less than a power of $2$. This isn't a problem since we can just "upgrade" the polynomial to one less than the next power of $2$.
					</p>

					<p>
						For example, if we have a polynomial $f(x) = a_0 + \dots + a_nx^n$ of degree $n$ and $2^k$ is the smallest power of $2$ at least as big as $n - 1$, then we can interpret $f(x)$ as $f(x) = a_0 + \dots a_nx^n + 0x^{n+1} + \dots + 0x^{2^k - 1}$.
					</p>

					<p>
						In the worst case, the new degree and the number of samples we'll have to take is doubled. This is fine because this is just a constant factor.
					</p>
				</div>
			</div>

			<div id="toc6" class="section">
				<div class="heading">Reducing Interpolating to Sampling</div>
				<div class="subsection">

					<p>
						While sampling can be easily done in $O(n^2)$, it seems like interpolating in any time complexity is a daunting task. However, in this section, we'll find that through the magic of primitive roots of unity, interpolating is just sampling in disguise.
					</p>

					<p>
						Let's first recap what the problem asks us to do.
					</p>

					<div class="block">
						<div class="block-heading">Interpolating Problem Statement</div>

					<p>
						Let $f(x) = a_0 + \dots + a_{n-1}x^{n-1}$ be a polynomial of degree $n - 1$.
					</p>

<br/>

					<p>
						Given $n$ sample points $s_0, \dots, s_{n-1}$ and $n$ samples $v_0, \dots, v_{n-1}$ where it is known that $f(s_0) = v_0, f(s_1) = v_1, \dots, f(s_{n-1}) = v_{n-1}$, we wish to find $a_0, \dots a_{n-1}$.
					</p>

<br/><br/>

					<p>
						In other words, we want to solve the system of equations
					</p>

					<p>
						$$\begin{align}a_0 + a_1s_0 + a_2s_0^2 + \dots + a_{n-1}s_0^{n-1} &= v_0 \\a_1 + a_1s_1 + a_2s_1^2 + \dots + a_{n-1}s_1^{n-1} &= v_1 \\\vdots\phantom{+$a_{n-1}s_1^{n-1}$}& \\a_1 + a_1s_{n-1} + a_2s_{n-1}^2 + \dots + a_{n-1}s_{n-1}^{n-1} &= v_{n-1} \\\end{align}$$
					</p>
					</div>

					<p>
						We note that by Uniqueness of Interpolation, that we're guaranteed exactly one possible value for $a_0, \dots, a_n$.
					</p>

					<p>
						Let's prove an interesting property about combining interpolating problems:
					</p>

					<div class="block">
						<div class="block-heading">Theorem - Additivity of Interpolation</div>

					<p>
						Let $f(x)$ and $g(x)$ be polynomials of degree $n - 1$.
					</p>

					<p>
						Suppose we are given sample points $s_0, \dots, s_n$ and we know that:
					</p>

					<p>
						$$u_0 = f(s_0), u_1 = f(s_1), \dots, u_{n-1} = f(s_{n-1}) \\v_0 = f(s_0), v_1 = f(s_1), \dots, v_{n-1} = f(s_{n-1})$$
					</p>

					<p>
						and we've found $f(x)$ and $g(x)$.
					</p>

					<p>
						Then the polynomial $h(x)$ that interpolates the samples $(u_0 + v_0), (u_1 + v_1), \dots, (u_{n-1}, v_{n-1})$ is $h(x) = f(x) + g(x)$.
					</p>
					</div>

					<p>
						The proof of this is pretty simple. At each of the sample points $s_i$ where $0 \leq i < n$, $h(s_i) = f(s_i) + g(s_i) = u_i + v_i$. Again, by the Uniquness of Interpolation, $h(x) = f(x) + g(x)$ is the only possible polynomial that interpolates the samples.
					</p>

					<p>
						This theorem seems trivial but it lets us break down the problem into easier subproblems. Let $v_0, \dots, v_n$ be samples. For $0 \leq k < n$, we'll define the <i>$k$-th partial sample set</i> to be $0, \dots, 0, v_k, 0, \dots, 0$. In other words, it's only the $k$-th sample and every other sample has been set to $0$.
					</p>

					<p>
						If we can solve the interpolation problem for all of the partial sample sets, we'll can just add the interpolating polynomials together to get the interpolation of $v_0, \dots, v_n$.
					</p>

					<p>
						Recall that we've picked $s_0, \dots, s_{n-1}$ to be $\om_n^0, \dots, \om_n^{n-1}$ where $\om_n$ is a primitive $n$-th root of unity. Now let's try to interpolate the $0$-th partial sample set, that is, we want to solve the system
					</p>

					<p>
						$$\begin{align}a_0 + a_1 + a_2 + \dots + a_{n-1}                                         &= v_0 \\a_0 + a_1\om_n^1 + a_2\om_n^2 + \dots + a_{n-1}\om_n^{n-1}                &= 0 \\            \vdots\phantom{+$a_{n-1}s_1^{n-1}$}               & \\a_0 + a_1\om_n^{n-1} + a_2\om_n^{2(n-1)} + \dots + a_{n-1}\om_n^{(n-1)^2} &= 0 \\\end{align}$$
					</p>

					<p>
						This doesn't make the problem any easier, but if we try something silly, we'll see that everything works out. If we set $a_0 = a_1 = a_2 = \dots = a_{n-1} = \frac 1n v_0$, then we see that indeed $a_0 + a_1 + a_2 + \dots + a_{n-1} = \frac 1nv_0 + \dots + \frac 1nv_0 = \frac 1nv_0(n) = v_0$.
					</p>

					<p>
						But do we satisfy the other equations? Well for $0 < k < n$, we have
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   a_0 + a_1\om_n^k + a_2\om_n^{2k} + \dots + a_{n-1}\om_n^{(n-1)k} \\&= \tfrac 1nv_0 + \tfrac 1nv_0\om_n^k + \tfrac 1nv_0\om_n^{2k} + \dots + \tfrac 1nv_0\om_n^{(n-1)k} \\&= \tfrac 1nv_0 \left(1 + \om_n^k + \om_n^{2k} + \dots + \om_n^{(n-1)k} \right)\end{align}$$
					</p>

					<p>
						By the fourth primitive root of unity property, for all $0 < k < n$, $\om_n^0 + \om_n^k + \om_n^{2k} + \dots + \om_n^{(n-1)k} = 0$, so
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   tfrac 1nv_0 \left(1 + \om_n^k + \om_n^{2k} + \dots + \om_n^{(n-1)k}\right) \\&= \tfrac 1nv_0 (0) \\&= 0\end{align}$$
					</p>

					<p>
						Now that we've solved the $0$-th partial sample set, we can also solve the $k$-th partial sample set for $0 < k < n$. This time, we want to solve the system
					</p>

					<p>
						$$\begin{align}a_0 + a_1 + a_2 + \dots + a_{n-1}                                         &= 0 \\                         \vdots\phantom{+$a_{n-1}s_1^{n-1}$}              & \\a_0 + a_1\om_n^k + a_2\om_n^{2k} + \dots + a_{n-1}\om_n^{(n-1)k}          &= v_k \\                         \vdots\phantom{+$a_{n-1}s_1^{n-1}$}              & \\a_0 + a_1\om_n^{n-1} + a_2\om_n^{2(n-1)} + \dots + a_{n-1}\om_n^{(n-1)^2} &= 0 \\\end{align}$$
					</p>

					<p>
						We can do something similar, but instead of setting $a_0 = \dots = a_n = \frac 1nv_0$, we'll set
					</p>

					<p>
						$$\begin{align}a_0 &= \tfrac 1nv_k \\a_1 &= \tfrac 1nv_k\om_n^{-k}\\ a_2 &= \tfrac 1nv_k\om_n^{-2k}\\ &\phantom{/}\vdots\\ a_{n-1} &= \tfrac 1nv_k \om_n^{-(n-1)k}\end{align}$$
					</p>

					<p>
						That way, we have
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   a_0 + a_1\om_n^k + a_2\om_n^{2k} + \dots + a_{n-1}\om^{(n-1)k} \\&= \tfrac 1nv_k + \tfrac 1nv_k\om_n^{-k}\om_n^k + \tfrac 1nv_k\om_n^{-2k}\om_n^{2k}+ \dots+ \tfrac 1nv_k \om_n^{-(n-1)k}\om_n^{-(n-1)k} \\&= \tfrac 1nv_k\left( 1 + \om_n^{-k}\om_n^k + \om_n^{-2k}\om_n^{2k} + \dots + \om_n^{-(n-1)k}\om_n^{(n-1)k}\right)\\&= \tfrac 1nv_k\left(1+1+1+\dots+1\right) \\&= \tfrac 1nv_k(n) \\&= v_k\end{align}$$
					</p>

					<p>
						And see once again for any $i \neq k$,
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   a_0 + a_1\om_n^i + a_2\om_n^{2i} + \dots + a_{n-1}\om_n^{(n-1)i} \\&= \tfrac 1nv_k + \tfrac 1nv_k\om_n^{-k}\om_n^i + \tfrac 1nv_k\om_n^{-2k}\om_n^{2i} + \dots + a_{n-1}\om_n^{-(n-1)k}\om_n^{(n-1)i} \\&= \tfrac 1nv_k \left(1 + \om_n^{-k}\om_n^i + \om_n^{-2k}\om_n^{2i} + \dots + \om_n^{-(n-1)k}\om_n^{(n-1)i}\right) \\&= \tfrac 1nv_k \left(1 + \om_n^{i-k} + \om_n^{2(i-k)} + \dots + \om_n^{(n-1)(i-k)} \right)\end{align}$$
					</p>

					<p>
						Let $j = i - k$, we have
					</p>

					<p>
						$$ \tfrac 1nv_k \left(1 + \om_n^{j} + \om_n^{2j} + \dots + \om_n^{(n-1)j} \right) $$
					</p>

					<p>
						We know that $0 \leq i, k < n$ and $i \neq k$, and there are 2 cases:
					</p>

<ol>

<li>

					<p>
						If $i > k$, then $0 < i - k < n$ or $0 < j < n$. Therefore,
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   \tfrac 1nv_k \left(1 + \om_n^{j} + \om_n^{2j} + \dots + \om_n^{(n-1)j} \right) \\&= \tfrac 1nv_k (0) \\&= 0\end{align}$$
					</p>

					<p>
						as required.
					</p>

</li>

<li>

					<p>
						If $i < k$, then $-n < i - k < 0$ or $-n < j < 0$. Adding $n$ to everything, we get $0 < j + n < n$.
					</p>

					<p>
						As a side note, we note that for any number $c$, $\om_n^{cn} = (\om_n^n)^c = 1^c = 1$.
					</p>

					<p>
						$$\begin{align}&\phantom{=.}   \tfrac 1nv_k \left(1 + \om_n^{j} + \om_n^{2j} + \dots + \om_n^{(n-1)j} \right) \\&= \tfrac 1nv_k \left(1 + \om_n^{j}\om_n^n + \om_n^{2j}\om_n^{2n} + \dots + \om_n^{(n-1)j}\om_n^{(n-1)n}\right) \\&= \tfrac 1nv_k \left(1 + \om_n^{j+n} + \om_n^{2(j + n)} +\dots+\om_n^{(n-1)(j + n)}\right) \\&= \tfrac 1nv_k (0) \\&= 0\end{align}$$
					</p>

					<p>
						as required.
					</p>

</li>

</ol>

					<p>
						To recap,
					</p>

					<div class="block">
						<div class="block-heading">Interpolation Formula</div>

					<p>
						Let $\om_n$ be a primitive $n$-th root of unity.
					</p>

<br/>

					<p>
						Let $v_0, \dots, v_{n-1}$ $n$ samples, with $v_k = f(\om_n^k)$ for all $0 \leq k < n$.
					</p>

<br/>

					<p>
						The solution to the $k$-th partial sample set is $a_i = \frac 1nv_k \om_n^{-ik}$ for all $0 \leq i < n$, that is
					</p>

					<p>
						$$\begin{align}f(x) &= \tfrac 1nv_k + \tfrac 1nv_k\om_n^{-k} + \tfrac 1nv_k\om_n^{-2k} + \dots + \tfrac 1nv_k\om_n^{-(n-1)k} \\     &= \tfrac 1nv_k \left(1 + \om_n^{-k} + \om_n^{-2k} + \dots + \om_n^{-(n-1)k} \right)\end{align}$$
					</p>

					<p>
						By the Additivity of Interpolation, the solution to $a_0, \dots, a_{n-1}$ is the sum of interpolations of all $n$ partial sample sets, that is
					</p>

					<p>
						$$\begin{align}a_0     &= \tfrac1n v_0 + \tfrac1n v_1 + \tfrac1n v_2 + \dots + \tfrac1n v_{n-1} \\a_1     &= \tfrac1n v_0 + \tfrac1n v_1\om_n^{-k} + \tfrac1n v_2\om_n^{-2k} + \dots + \tfrac1n v_{n-1}\om_n^{-(n-1)k} \\a_2     &= \tfrac1n v_0 + \tfrac1n v_1\om_n^{-2k} + \tfrac1n v_2\om_n^{-4k} + \dots + \tfrac1n v_{n-1}\om_n^{-2(n-1)k} \\        &                              \phantom{XXXXXXXXXXXX}\vdots \\a_{n-1} &= \tfrac1n v_0 + \tfrac1n v_1\om_n^{-(n-1)k} + \tfrac1n v_2\om_n^{-2(n-1)k} + \dots + \tfrac1n v_{n-1}\om_n^{-(n-1)^2k} \\\end{align}$$
					</p>

					<p>
						Pulling out $\frac 1n$ from each term, we get
					</p>

					<p>
						$$\begin{align}a_0     &= \tfrac 1n \left( v_0 +  v_1 +  v_2 + \dots +  v_{n-1} \right) \\a_1     &= \tfrac 1n \left( v_0 +  v_1\om_n^{-k} +  v_2\om_n^{-2k} + \dots +  v_{n-1}\om_n^{-(n-1)k} \right) \\a_2     &= \tfrac 1n \left( v_0 +  v_1\om_n^{-2k} +  v_2\om_n^{-4k} + \dots +  v_{n-1}\om_n^{-2(n-1)k} \right) \\        &                           \phantom{XXXXXXXXXXXX}\vdots \\a_{n-1} &= \tfrac 1n \left( v_0 +  v_1\om_n^{-(n-1)k} +  v_2\om_n^{-2(n-1)k} + \dots +  v_{n-1}\om_n^{-(n-1)^2k} \right)\\\end{align}$$
					</p>
					</div>

					<p>
						Ignoring the factor of $\frac 1n$, this equation looks an awful lot like the sampling problem.
					</p>
				</div>
			</div>

			<div id="toc7" class="section">
				<div class="heading">Interpolating Quickly</div>
				<div class="subsection">

					<p>
						We can now use the techniques we used to sample quickly to interpolate quickly. Let's pretend the factor of $\frac 1n$ doesn't exist. Then from the previous section, we found that for all $0 \leq k < n$,
					</p>

					<p>
						$$ a_{k} = v_0 + v_1\om_n^{-k} + v_2\om_n^{-2k} + \dots + v_{n-1}\om_{n-1}^{-(n-1)k} $$
					</p>

					<p>
						This is almost exactly what we wanted to compute when sampling, except $a_k$ and $v_k$ are swapped and the exponents are negative in this version. In fact, if we define a special polynomial
					</p>

					<p>
						$$ v(x) = v_0 + v_1x + v_2x^2 + \dots + v_{n-1}x^{n-1} $$
					</p>

					<p>
						Then we notice that $a_k = f(\om_n^{-k})$, and we want to find $a_k$ for all $0 \leq k < n$, which is a sampling problem.
					</p>

					<p>
						Using the strategies from sampling quickly, we'll once again define
					</p>
				</div>
			</div>

		</div>
	</body>
</html>